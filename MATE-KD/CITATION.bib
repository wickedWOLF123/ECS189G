@misc{mate-kd-2024,
  title={MATE-KD: Multi-teacher Attribution-weighted Knowledge Distillation},
  author={Your Name and Collaborator Names},
  year={2024},
  url={https://github.com/yourusername/MATE-KD},
  note={Implementation of attribution-weighted knowledge distillation using Grad-CAM similarity for dynamic teacher weighting}
}

@article{mate-kd-paper-2024,
  title={MATE-KD: Multi-teacher Attribution-weighted Knowledge Distillation for Efficient Deep Learning},
  author={Your Name and Collaborator Names},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2024},
  abstract={We present MATE-KD, a novel approach to knowledge distillation that dynamically weights multiple teacher models based on attribution similarity. Our method uses Grad-CAM maps to compute real-time similarity between student and teacher attention patterns, enabling adaptive knowledge transfer. Experiments on CIFAR-10 show that our ResNet20 student achieves 90.22\% accuracy while maintaining significantly reduced parameters compared to teacher models.}
}

% Related work citations

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{you2017learning,
  title={Learning from multiple teacher networks},
  author={You, Shan and Xu, Chang and Xu, Chao and Tao, Dacheng},
  booktitle={Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1285--1294},
  year={2017}
}

@article{romero2014fitnets,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}

@article{zagoruyko2016attention,
  title={Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1612.03928},
  year={2016}
}

% Datasets

@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  institution={Citeseer}
}

@article{hendrycks2019robustness,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1903.12261},
  year={2019}
}

% Model architectures

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
} 